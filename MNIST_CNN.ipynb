{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b86eb92",
   "metadata": {},
   "source": [
    "# CNN MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49752987",
   "metadata": {},
   "source": [
    "### Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0aa035be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d6f06bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing MNIST dataset from keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "deefec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset into train and test sets\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bd2f8370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "(60000, 28, 28) (60000,)\n",
      "test data\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data\")\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(\"test data\")\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87246bd",
   "metadata": {},
   "source": [
    "We have 60000 training images and 10000 test images each of size 28X28. Now since the images are only grey scale, the matrix representation is grey scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0ffb0478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28, 28) (20000,)\n"
     ]
    }
   ],
   "source": [
    "# selecting 20000 images from training dataset randomly to speed up training.\n",
    "img=np.random.randint(x_train.shape[0],size=20000)\n",
    "x_train=x_train[img,:]\n",
    "y_train=y_train[img]\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efdd914",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "\n",
    "### Reshaping data\n",
    "Since the images are of size (28,28,1) the training data x_train needs to be of shape (20000,28,28,1). Had there been coloured images the size of the dataset would be (20000,28,28,3).\n",
    "\n",
    "Also since all of the images have 0-9 label, y_train needs to be of shape (20000,10), where each image is represented by as a 10-d one hot encoded vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7e13c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the input shape\n",
    "img_rows,img_cols=28,28\n",
    "input_shape=(img_rows,img_cols,1)\n",
    "\n",
    "# batch size, number of classes, epochs\n",
    "batch_size=128\n",
    "num_classes=10\n",
    "epochs=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d3fe6db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape x_train, x_test\n",
    "x_train=x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
    "x_test=x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dd81b6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# converting y_train and y_test to one hot encoded vectors\n",
    "from keras import utils as np_utils\n",
    "\n",
    "y_train=keras.utils.np_utils.to_categorical(y_train,num_classes)\n",
    "y_test=keras.utils.np_utils.to_categorical(y_test,num_classes)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b779af6",
   "metadata": {},
   "source": [
    "### Converting the datatypes of images from int to float\n",
    "It is advisable to feed the data as float. This is not really compulsory, but advisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "44267ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "print(x_test.dtype)\n",
    "print(x_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555c426",
   "metadata": {},
   "source": [
    "### Normalizing\n",
    "The value of each pixel is between 0-255, so we will rescale each pixel by dividing by 255 so that the range becomes 0-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cf5424b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c063a1e",
   "metadata": {},
   "source": [
    "## Building Model\n",
    "\n",
    "Building a shallow CNN having:\n",
    "\n",
    "1) Two convolution layers with 32 and 64 filters respectively.\n",
    "\n",
    "2) Followed by a MaxPooling layer\n",
    "\n",
    "3) Flatten the network to give a long vector\n",
    "\n",
    "4) Fully connected dense layer with 128 neurons\n",
    "\n",
    "5) A softmax layer with 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bfeadd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_35 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 12, 12, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#keras convolution layer is called conv2D\n",
    "#first convolution layer\n",
    "model.add(Conv2D(32,kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape\n",
    "                ))\n",
    "# second layer\n",
    "model.add(Conv2D(64,kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                ))\n",
    "# adding maxpool layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten and add a fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# softmax layer\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea522c0",
   "metadata": {},
   "source": [
    "## Fitting and evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "31ae12be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "157/157 [==============================] - 19s 120ms/step - loss: 2.3038 - accuracy: 0.1163 - val_loss: 2.2846 - val_accuracy: 0.1656\n",
      "Epoch 2/12\n",
      "157/157 [==============================] - 19s 118ms/step - loss: 2.2812 - accuracy: 0.1507 - val_loss: 2.2594 - val_accuracy: 0.2393\n",
      "Epoch 3/12\n",
      "157/157 [==============================] - 19s 119ms/step - loss: 2.2562 - accuracy: 0.1973 - val_loss: 2.2331 - val_accuracy: 0.3592\n",
      "Epoch 4/12\n",
      "157/157 [==============================] - 18s 116ms/step - loss: 2.2312 - accuracy: 0.2394 - val_loss: 2.2050 - val_accuracy: 0.4612\n",
      "Epoch 5/12\n",
      "157/157 [==============================] - 18s 117ms/step - loss: 2.2059 - accuracy: 0.2810 - val_loss: 2.1747 - val_accuracy: 0.5262\n",
      "Epoch 6/12\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 2.1766 - accuracy: 0.3216 - val_loss: 2.1412 - val_accuracy: 0.5678\n",
      "Epoch 7/12\n",
      "157/157 [==============================] - 19s 119ms/step - loss: 2.1463 - accuracy: 0.3609 - val_loss: 2.1045 - val_accuracy: 0.6064\n",
      "Epoch 8/12\n",
      "157/157 [==============================] - 19s 119ms/step - loss: 2.1115 - accuracy: 0.3887 - val_loss: 2.0642 - val_accuracy: 0.6342\n",
      "Epoch 9/12\n",
      "157/157 [==============================] - 19s 119ms/step - loss: 2.0721 - accuracy: 0.4248 - val_loss: 2.0197 - val_accuracy: 0.6562\n",
      "Epoch 10/12\n",
      "157/157 [==============================] - 19s 120ms/step - loss: 2.0301 - accuracy: 0.4498 - val_loss: 1.9701 - val_accuracy: 0.6748\n",
      "Epoch 11/12\n",
      "157/157 [==============================] - 19s 120ms/step - loss: 1.9831 - accuracy: 0.4730 - val_loss: 1.9156 - val_accuracy: 0.6901\n",
      "Epoch 12/12\n",
      "157/157 [==============================] - 19s 121ms/step - loss: 1.9284 - accuracy: 0.4992 - val_loss: 1.8560 - val_accuracy: 0.7061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d2e267970>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using cross entropy loss, any optimizer like adam, rmsprop and metric is accuracy\n",
    "from tensorflow import keras\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.Adadelta(),\n",
    "             metrics=['accuracy'])\n",
    "# fitting the model\n",
    "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "         validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71699efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 1.8560 - accuracy: 0.7061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.856016755104065, 0.7060999870300293]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the data on test data\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "41d0ca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec729381",
   "metadata": {},
   "source": [
    "The final loss (on test data) is about 1.85 and the accuracy is 70.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
